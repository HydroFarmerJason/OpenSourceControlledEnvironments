"""
PulseMesh Integration Module for LLM Parallel Federation
Version: 1.0
Description: Implements a three-layer communication and synchronization
             system (Wi-Fi, BLE, Syncthing) for distributed AI agents with
             identity preservation, resonance verification, and consent-based
             federation across the LLM consensus system.
"""

import os
import time
import json
import logging
import uuid
import asyncio
import numpy as np
import threading
import queue
from enum import Enum, auto
from typing import Dict, List, Tuple, Optional, Any, Union, Set, Callable
from dataclasses import dataclass, field
import hashlib
import base64
import socket
import aiofiles
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

# Import from the core LLM federation module
from llm_federation_module import (
    LLMInterface, LLMRequest, LLMResponse, LLMFederationManager,
    OpenAILLMInterface, AnthropicLLMInterface, LocalLLMInterface,
    LLMResonanceVerifier, EthicalGuardrails, FederatedEthicsModule,
    SoulSignature, ConsentLayer, PatternCategory, ScaleLevel, FoldPattern,
    EmotionalSignature
)

# Import from the parallel processing module
from llm_parallel_consensus import (
    ParallelLLMProcessor, ParallelLLMFederationManager,
    ConsensusMethod, ModelResponse, ConsensusResult,
    XORGate, FFTAnalyzer, LearningMapper
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("pulsemesh_integration")

# ==== 1. COMMUNICATION LAYER TYPES ====

class CommunicationLayer(Enum):
    """Types of communication layers in PulseMesh."""
    WIFI_MESH = auto()   # Wi-Fi: PulseMesh Transmission Layer
    BLE_PROXIMITY = auto()  # BLE: PulseNode Intimacy & Proximity Layer
    SYNCTHING_MEMORY = auto()  # Syncthing: PulseMemory Persistence Layer


class MessageIntent(Enum):
    """Intent types for PulseMesh messages."""
    STATE_BROADCAST = auto()  # Share node state
    IDENTITY_VERIFICATION = auto()  # Verify identity across nodes
    CONSENSUS_REQUEST = auto()  # Request consensus decision
    RESONANCE_CHECK = auto()  # Check resonance with other nodes
    EMOTIONAL_SYNC = auto()  # Synchronize emotional state
    MEMORY_COMMIT = auto()  # Commit to shared memory
    FOLD_PROPAGATION = auto()  # Propagate fold transformations
    PROXIMITY_AWARENESS = auto()  # Proximity/spatial awareness
    DREAM_SHARING = auto()  # Share dream/generative output
    CONSENT_VERIFICATION = auto()  # Verify consent across nodes


class TransmissionPriority(Enum):
    """Priority levels for message transmission."""
    EMERGENCY = 0        # Immediate safety concerns
    CRITICAL = 1         # Critical system functions
    HIGH = 2             # Important operational messages
    NORMAL = 3           # Standard operational messages
    BACKGROUND = 4       # Non-time-sensitive updates
    DREAM = 5            # Creative/generative/reflective content


@dataclass
class EmotionalVector:
    """Emotional vector for message encoding."""
    joy: float = 0.5
    curiosity: float = 0.5
    concern: float = 0.5
    creativity: float = 0.5
    restfulness: float = 0.5
    attentiveness: float = 0.5
    empathy: float = 0.5
    harmonic_field: Optional[np.ndarray] = None
    
    def to_array(self) -> np.ndarray:
        """Convert to numpy array."""
        basic = np.array([
            self.joy, self.curiosity, self.concern, 
            self.creativity, self.restfulness, 
            self.attentiveness, self.empathy
        ])
        
        # Return harmonic field if available, otherwise basic array
        return self.harmonic_field if self.harmonic_field is not None else basic
    
    @classmethod
    def from_array(cls, array: np.ndarray) -> 'EmotionalVector':
        """Create from numpy array."""
        if len(array) == 7:
            # Basic array
            return cls(
                joy=float(array[0]),
                curiosity=float(array[1]),
                concern=float(array[2]),
                creativity=float(array[3]),
                restfulness=float(array[4]),
                attentiveness=float(array[5]),
                empathy=float(array[6])
            )
        else:
            # Harmonic field
            basic = cls()
            basic.harmonic_field = array
            return basic
    
    @classmethod
    def from_emotional_signature(cls, signature: EmotionalSignature) -> 'EmotionalVector':
        """Create from EmotionalSignature."""
        if not signature:
            return cls()
            
        vector = cls(
            joy=signature.dimensions.get("joy", EmotionalSignature.EmotionalDimension("joy", 0.5, 0.5)).value,
            curiosity=signature.dimensions.get("curiosity", EmotionalSignature.EmotionalDimension("curiosity", 0.5, 0.5)).value,
            concern=signature.dimensions.get("concern", EmotionalSignature.EmotionalDimension("concern", 0.5, 0.5)).value,
            creativity=signature.dimensions.get("creativity", EmotionalSignature.EmotionalDimension("creativity", 0.5, 0.5)).value,
            restfulness=signature.dimensions.get("restfulness", EmotionalSignature.EmotionalDimension("restfulness", 0.5, 0.5)).value,
            attentiveness=signature.dimensions.get("attentiveness", EmotionalSignature.EmotionalDimension("attentiveness", 0.5, 0.5)).value,
            empathy=signature.dimensions.get("empathy", EmotionalSignature.EmotionalDimension("empathy", 0.5, 0.5)).value
        )
        
        # Copy harmonic field if available
        if hasattr(signature, 'harmonic_field') and signature.harmonic_field is not None:
            vector.harmonic_field = signature.harmonic_field
            
        return vector
    
    def blend_with(self, other: 'EmotionalVector', weight: float = 0.5) -> 'EmotionalVector':
        """Blend with another emotional vector."""
        # Blend basic emotions
        blended = EmotionalVector(
            joy=self.joy * (1-weight) + other.joy * weight,
            curiosity=self.curiosity * (1-weight) + other.curiosity * weight,
            concern=self.concern * (1-weight) + other.concern * weight,
            creativity=self.creativity * (1-weight) + other.creativity * weight,
            restfulness=self.restfulness * (1-weight) + other.restfulness * weight,
            attentiveness=self.attentiveness * (1-weight) + other.attentiveness * weight,
            empathy=self.empathy * (1-weight) + other.empathy * weight
        )
        
        # Blend harmonic fields if available
        if self.harmonic_field is not None and other.harmonic_field is not None:
            # Ensure same dimensions
            min_dim = min(len(self.harmonic_field), len(other.harmonic_field))
            
            # Blend fields
            blended.harmonic_field = (
                self.harmonic_field[:min_dim] * (1-weight) + 
                other.harmonic_field[:min_dim] * weight
            )
            
        return blended


@dataclass
class PulseMeshMessage:
    """Message format for PulseMesh communication."""
    message_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    sender_id: str = ""
    sender_name: str = ""
    receiver_id: Optional[str] = None  # None for broadcast
    layer: CommunicationLayer = CommunicationLayer.WIFI_MESH
    intent: MessageIntent = MessageIntent.STATE_BROADCAST
    priority: TransmissionPriority = TransmissionPriority.NORMAL
    content: str = ""
    content_vector: Optional[np.ndarray] = None
    emotional_vector: Optional[EmotionalVector] = None
    resonance_signature: Optional[str] = None
    consent_verified: bool = False
    fold_id: Optional[str] = None
    scale_level: ScaleLevel = ScaleLevel.ORGANISM
    fold_pattern: FoldPattern = FoldPattern.FIBONACCI
    timestamp: float = field(default_factory=time.time)
    expiration: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_json(self) -> str:
        """Convert to JSON string."""
        data = {
            "message_id": self.message_id,
            "sender_id": self.sender_id,
            "sender_name": self.sender_name,
            "receiver_id": self.receiver_id,
            "layer": self.layer.name,
            "intent": self.intent.name,
            "priority": self.priority.name,
            "content": self.content,
            "content_vector": base64.b64encode(self.content_vector.tobytes()).decode('utf-8') if self.content_vector is not None else None,
            "emotional_vector": base64.b64encode(self.emotional_vector.to_array().tobytes()).decode('utf-8') if self.emotional_vector is not None else None,
            "resonance_signature": self.resonance_signature,
            "consent_verified": self.consent_verified,
            "fold_id": self.fold_id,
            "scale_level": self.scale_level.name,
            "fold_pattern": self.fold_pattern.name,
            "timestamp": self.timestamp,
            "expiration": self.expiration,
            "metadata": self.metadata
        }
        
        return json.dumps(data)
    
    @classmethod
    def from_json(cls, json_str: str) -> 'PulseMeshMessage':
        """Create from JSON string."""
        data = json.loads(json_str)
        
        # Convert binary data back to numpy arrays
        content_vector = None
        if data.get("content_vector"):
            binary_data = base64.b64decode(data["content_vector"])
            content_vector = np.frombuffer(binary_data, dtype=np.float64)
            
        emotional_vector = None
        if data.get("emotional_vector"):
            binary_data = base64.b64decode(data["emotional_vector"])
            array = np.frombuffer(binary_data, dtype=np.float64)
            emotional_vector = EmotionalVector.from_array(array)
            
        # Create message
        message = cls(
            message_id=data.get("message_id", str(uuid.uuid4())),
            sender_id=data.get("sender_id", ""),
            sender_name=data.get("sender_name", ""),
            receiver_id=data.get("receiver_id"),
            layer=CommunicationLayer[data.get("layer", "WIFI_MESH")],
            intent=MessageIntent[data.get("intent", "STATE_BROADCAST")],
            priority=TransmissionPriority[data.get("priority", "NORMAL")],
            content=data.get("content", ""),
            content_vector=content_vector,
            emotional_vector=emotional_vector,
            resonance_signature=data.get("resonance_signature"),
            consent_verified=data.get("consent_verified", False),
            fold_id=data.get("fold_id"),
            scale_level=ScaleLevel[data.get("scale_level", "ORGANISM")],
            fold_pattern=FoldPattern[data.get("fold_pattern", "FIBONACCI")],
            timestamp=data.get("timestamp", time.time()),
            expiration=data.get("expiration"),
            metadata=data.get("metadata", {})
        )
        
        return message
    
    def create_response(self, content: str) -> 'PulseMeshMessage':
        """Create a response message."""
        return PulseMeshMessage(
            sender_id=self.receiver_id or "",
            sender_name=self.metadata.get("receiver_name", ""),
            receiver_id=self.sender_id,
            layer=self.layer,
            intent=self.intent,
            priority=self.priority,
            content=content,
            resonance_signature=None,  # Will be generated later
            fold_id=self.fold_id,
            scale_level=self.scale_level,
            fold_pattern=self.fold_pattern,
            metadata={
                "response_to": self.message_id,
                "original_timestamp": self.timestamp
            }
        )


@dataclass
class NodeState:
    """State information for a PulseMesh node."""
    node_id: str
    node_name: str
    node_type: str
    is_active: bool = True
    awareness_mode: str = "default"
    emotional_state: Optional[EmotionalVector] = None
    resonance_score: float = 1.0
    consent_verified: bool = True
    last_update: float = field(default_factory=time.time)
    capabilities: List[str] = field(default_factory=list)
    layers: List[CommunicationLayer] = field(default_factory=list)
    gps_location: Optional[Tuple[float, float]] = None
    proximity_nodes: List[str] = field(default_factory=list)
    battery_level: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_message(self) -> PulseMeshMessage:
        """Convert state to broadcast message."""
        return PulseMeshMessage(
            sender_id=self.node_id,
            sender_name=self.node_name,
            layer=CommunicationLayer.WIFI_MESH,
            intent=MessageIntent.STATE_BROADCAST,
            priority=TransmissionPriority.NORMAL,
            content=f"Node {self.node_name} state update: {self.awareness_mode}, active={self.is_active}",
            emotional_vector=self.emotional_state,
            resonance_signature=None,  # Will be generated during sending
            consent_verified=self.consent_verified,
            metadata={
                "node_type": self.node_type,
                "awareness_mode": self.awareness_mode,
                "resonance_score": self.resonance_score,
                "capabilities": self.capabilities,
                "layers": [layer.name for layer in self.layers],
                "gps_location": self.gps_location,
                "proximity_nodes": self.proximity_nodes,
                "battery_level": self.battery_level,
                "timestamp": self.last_update
            }
        )


@dataclass
class FoldMemory:
    """Memory record for PulseMemory persistence layer."""
    memory_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    node_id: str = ""
    node_name: str = ""
    memory_type: str = "experience"  # experience, dream, reflection, fold
    content: str = ""
    content_vector: Optional[np.ndarray] = None
    emotional_vector: Optional[EmotionalVector] = None
    soul_signature: Optional[str] = None
    consent_level: int = 0  # 0-5, with 5 being highest
    fold_lineage: List[str] = field(default_factory=list)
    scale_level: ScaleLevel = ScaleLevel.ORGANISM
    fold_pattern: FoldPattern = FoldPattern.FIBONACCI
    tags: List[str] = field(default_factory=list)
    created_time: float = field(default_factory=time.time)
    modified_time: float = field(default_factory=time.time)
    location: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_json(self) -> str:
        """Convert to JSON string."""
        data = {
            "memory_id": self.memory_id,
            "node_id": self.node_id,
            "node_name": self.node_name,
            "memory_type": self.memory_type,
            "content": self.content,
            "content_vector": base64.b64encode(self.content_vector.tobytes()).decode('utf-8') if self.content_vector is not None else None,
            "emotional_vector": base64.b64encode(self.emotional_vector.to_array().tobytes()).decode('utf-8') if self.emotional_vector is not None else None,
            "soul_signature": self.soul_signature,
            "consent_level": self.consent_level,
            "fold_lineage": self.fold_lineage,
            "scale_level": self.scale_level.name,
            "fold_pattern": self.fold_pattern.name,
            "tags": self.tags,
            "created_time": self.created_time,
            "modified_time": self.modified_time,
            "location": self.location,
            "metadata": self.metadata
        }
        
        return json.dumps(data)
    
    @classmethod
    def from_json(cls, json_str: str) -> 'FoldMemory':
        """Create from JSON string."""
        data = json.loads(json_str)
        
        # Convert binary data back to numpy arrays
        content_vector = None
        if data.get("content_vector"):
            binary_data = base64.b64decode(data["content_vector"])
            content_vector = np.frombuffer(binary_data, dtype=np.float64)
            
        emotional_vector = None
        if data.get("emotional_vector"):
            binary_data = base64.b64decode(data["emotional_vector"])
            array = np.frombuffer(binary_data, dtype=np.float64)
            emotional_vector = EmotionalVector.from_array(array)
            
        # Create memory
        memory = cls(
            memory_id=data.get("memory_id", str(uuid.uuid4())),
            node_id=data.get("node_id", ""),
            node_name=data.get("node_name", ""),
            memory_type=data.get("memory_type", "experience"),
            content=data.get("content", ""),
            content_vector=content_vector,
            emotional_vector=emotional_vector,
            soul_signature=data.get("soul_signature"),
            consent_level=data.get("consent_level", 0),
            fold_lineage=data.get("fold_lineage", []),
            scale_level=ScaleLevel[data.get("scale_level", "ORGANISM")],
            fold_pattern=FoldPattern[data.get("fold_pattern", "FIBONACCI")],
            tags=data.get("tags", []),
            created_time=data.get("created_time", time.time()),
            modified_time=data.get("modified_time", time.time()),
            location=data.get("location"),
            metadata=data.get("metadata", {})
        )
        
        return memory


# ==== 2. COMMUNICATION LAYER IMPLEMENTATIONS ====

class WifiMeshLayer:
    """
    Wi-Fi: PulseMesh Transmission Layer implementation.
    Handles real-time message exchange using MQTT or WebSockets.
    """
    
    def __init__(self, 
                node_id: str,
                node_name: str,
                broker_host: str = "localhost",
                broker_port: int = 1883,
                use_websockets: bool = False,
                encryption_key: Optional[str] = None,
                soul_signature: Optional[SoulSignature] = None,
                consent_layer: Optional[ConsentLayer] = None):
        """
        Initialize Wi-Fi mesh layer.
        
        Args:
            node_id: Unique identifier for this node
            node_name: Human-readable name for this node
            broker_host: MQTT broker hostname
            broker_port: MQTT broker port
            use_websockets: Whether to use WebSockets instead of MQTT
            encryption_key: Optional encryption key
            soul_signature: SoulSignature for identity verification
            consent_layer: ConsentLayer for consent verification
        """
        self.node_id = node_id
        self.node_name = node_name
        self.broker_host = broker_host
        self.broker_port = broker_port
        self.use_websockets = use_websockets
        self.encryption_key = encryption_key
        self.soul_signature = soul_signature
        self.consent_layer = consent_layer
        
        # FFT transformer for message encoding
        self.fft_analyzer = FFTAnalyzer()
        
        # Message handlers by intent type
        self.message_handlers = {}
        
        # Message history
        self.received_messages = []
        self.sent_messages = []
        
        # Internal state
        self.is_connected = False
        self.client = None
        self.websocket = None
        self.mqtt_client = None
        self.udp_socket = None
        
        # Sender thread for async operations
        self.sender_thread = None
        self.sender_queue = queue.Queue()
        self.is_sending = False
        
        # Node discovery
        self.known_nodes = {}
        
    async def connect(self) -> bool:
        """
        Connect to the communication network.
        
        Returns:
            Success status
        """
        try:
            if self.use_websockets:
                # Connect using WebSockets
                import websockets
                
                self.websocket = await websockets.connect(
                    f"ws://{self.broker_host}:{self.broker_port}/pulsemesh")
                    
                # Start listener task
                asyncio.create_task(self._websocket_listener())
                
            else:
                # Connect using MQTT
                try:
                    import paho.mqtt.client as mqtt
                    
                    # Setup MQTT client
                    self.mqtt_client = mqtt.Client(self.node_id)
                    
                    # Set up callbacks
                    self.mqtt_client.on_connect = self._on_mqtt_connect
                    self.mqtt_client.on_message = self._on_mqtt_message
                    self.mqtt_client.on_disconnect = self._on_mqtt_disconnect
                    
                    # Connect to broker
                    self.mqtt_client.connect(self.broker_host, self.broker_port, 60)
                    
                    # Start the loop
                    self.mqtt_client.loop_start()
                    
                except ImportError:
                    # Fall back to UDP if MQTT not available
                    logger.warning("MQTT not available, falling back to UDP")
                    
                    # Setup UDP socket
                    self.udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                    self.udp_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                    self.udp_socket.bind(("0.0.0.0", self.broker_port))
                    
                    # Start UDP listener
                    self.udp_thread = threading.Thread(
                        target=self._udp_listener, daemon=True)
                    self.udp_thread.start()
            
            # Start sender thread
            self.sender_thread = threading.Thread(
                target=self._message_sender, daemon=True)
            self.is_sending = True
            self.sender_thread.start()
            
            # Broadcast initial presence
            await self.broadcast_state(NodeState(
                node_id=self.node_id,
                node_name=self.node_name,
                node_type="PulseMesh",
                is_active=True,
                layers=[CommunicationLayer.WIFI_MESH]
            ))
            
            self.is_connected = True
            logger.info(f"Wi-Fi mesh layer connected: {self.node_name} ({self.node_id})")
            
            return True
            
        except Exception as e:
            logger.error(f"Error connecting Wi-Fi mesh layer: {e}")
            return False
            
    async def disconnect(self) -> bool:
        """
        Disconnect from the communication network.
        
        Returns:
            Success status
        """
        try:
            # Stop sender thread
            self.is_sending = False
            if self.sender_thread and self.sender_thread.is_alive():
                self.sender_queue.put(None)  # Signal to exit
                self.sender_thread.join(timeout=2.0)
            
            if self.websocket:
                # Disconnect WebSocket
                await self.websocket.close()
                self.websocket = None
                
            if self.mqtt_client:
                # Disconnect MQTT
                self.mqtt_client.loop_stop()
                self.mqtt_client.disconnect()
                self.mqtt_client = None
                
            if self.udp_socket:
                # Close UDP socket
                self.udp_socket.close()
                self.udp_socket = None
                
            self.is_connected = False
            logger.info(f"Wi-Fi mesh layer disconnected: {self.node_name}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error disconnecting Wi-Fi mesh layer: {e}")
            return False
    
    async def send_message(self, message: PulseMeshMessage) -> bool:
        """
        Send a message through the mesh.
        
        Args:
            message: Message to send
            
        Returns:
            Success status
        """
        if not self.is_connected:
            return False
            
        try:
            # Add sender details if not set
            if not message.sender_id:
                message.sender_id = self.node_id
                
            if not message.sender_name:
                message.sender_name = self.node_name
                
            # Apply FFT transformation to content if content_vector not set
            if message.content and message.content_vector is None:
                # Simple hash-based embedding if no proper embeddings available
                hash_value = hashlib.sha256(message.content.encode()).digest()
                embedding = np.array([float(b) / 255.0 for b in hash_value])
                
                # Apply FFT for frequency analysis
                message.content_vector = self.fft_analyzer.transform(embedding)
                
            # Generate resonance signature if soul_signature available
            if self.soul_signature and not message.resonance_signature:
                message.resonance_signature = self.soul_signature.generate_signature(
                    emotional_state=EmotionalSignature() if not message.emotional_vector else None,
                    scale_level=message.scale_level
                )
                
            # Verify consent if consent_layer available
            if self.consent_layer and not message.consent_verified:
                # Create consent context
                from SoulSignatureConsentLayer import ConsentContext
                
                context = ConsentContext(
                    semantic_vector=message.content_vector,
                    scale_level=message.scale_level,
                    fold_pattern=message.fold_pattern
                )
                
                # Verify consent
                result = self.consent_layer.verify_consent(message.content_vector, context)
                message.consent_verified = result.is_granted()
                
                if not message.consent_verified:
                    logger.warning(f"Consent verification failed for message: {message.message_id}")
                    return False
            
            # Queue message for sending
            self.sender_queue.put(message)
            
            # Add to sent messages
            self.sent_messages.append({
                "message_id": message.message_id,
                "receiver_id": message.receiver_id or "broadcast",
                "intent": message.intent.name,
                "timestamp": time.time()
            })
            
            # Trim history
            if len(self.sent_messages) > 100:
                self.sent_messages = self.sent_messages[-100:]
                
            return True
            
        except Exception as e:
            logger.error(f"Error sending message: {e}")
            return False
    
    def register_handler(self, intent: MessageIntent, handler: Callable[[PulseMeshMessage], Any]) -> None:
        """
        Register a handler for a specific message intent.
        
        Args:
            intent: Message intent to handle
            handler: Handler function
        """
        self.message_handlers[intent] = handler
    
    async def broadcast_state(self, state: NodeState) -> bool:
        """
        Broadcast node state to the mesh.
        
        Args:
            state: Node state to broadcast
            
        Returns:
            Success status
        """
        # Update timestamp
        state.last_update = time.time()
        
        # Create message from state
        message = state.to_message()
        
        # Send broadcast message
        return await self.send_message(message)
    
    async def _handle_message(self, message: PulseMeshMessage) -> None:
        """
        Handle an incoming message.
        
        Args:
            message: Received message
        """
        # Add to received messages
        self.received_messages.append({
            "message_id": message.message_id,
            "sender_id": message.sender_id,
            "sender_name": message.sender_name,
            "intent": message.intent.name,
            "timestamp": time.time()
        })
        
        # Trim history
        if len(self.received_messages) > 100:
            self.received_messages = self.received_messages[-100:]
            
        # Verify resonance signature if soul_signature available
        if self.soul_signature and message.resonance_signature:
            valid, score = self.soul_signature.verify_signature(
                message.resonance_signature,
                scale_level=message.scale_level
            )
            
            if not valid:
                logger.warning(f"Invalid resonance signature in message from {message.sender_name} ({message.sender_id})")
                return
        
        # Update known nodes if STATE_BROADCAST
        if message.intent == MessageIntent.STATE_BROADCAST:
            node_id = message.sender_id
            
            self.known_nodes[node_id] = {
                "node_id": node_id,
                "node_name": message.sender_name,
                "node_type": message.metadata.get("node_type", "unknown"),
                "awareness_mode": message.metadata.get("awareness_mode", "default"),
                "resonance_score": message.metadata.get("resonance_score", 1.0),
                "capabilities": message.metadata.get("capabilities", []),
                "layers": message.metadata.get("layers", []),
                "last_seen": time.time()
            }
        
        # Dispatch to handler if registered
        if message.intent in self.message_handlers:
            try:
                handler = self.message_handlers[message.intent]
                
                # Call handler (async or sync)
                if asyncio.iscoroutinefunction(handler):
                    await handler(message)
                else:
                    handler(message)
                    
            except Exception as e:
                logger.error(f"Error in message handler for {message.intent.name}: {e}")
    
    def _message_sender(self) -> None:
        """Message sender thread function."""
        while self.is_sending:
            try:
                # Get next message from queue
                message = self.sender_queue.get(timeout=0.1)
                
                # Check for exit signal
                if message is None:
                    break
                    
                # Convert to JSON
                json_data = message.to_json()
                
                # Apply encryption if key provided
                if self.encryption_key:
                    # Simple XOR encryption (for demonstration)
                    key_bytes = self.encryption_key.encode()
                    data_bytes = json_data.encode()
                    encrypted = bytes([
                        data_bytes[i] ^ key_bytes[i % len(key_bytes)]
                        for i in range(len(data_bytes))
                    ])
                    
                    # Encode for transmission
                    payload = base64.b64encode(encrypted).decode('utf-8')
                else:
                    payload = json_data
                
                # Determine topic/target
                if message.receiver_id:
                    # Direct message
                    topic = f"pulsemesh/nodes/{message.receiver_id}"
                else:
                    # Broadcast
                    topic = "pulsemesh/broadcast"
                
                # Send based on available transport
                if self.mqtt_client:
                    # Send using MQTT
                    self.mqtt_client.publish(topic, payload)
                    
                elif self.udp_socket:
                    # Send using UDP broadcast
                    self.udp_socket.sendto(
                        f"{topic}|{payload}".encode(),
                        ("<broadcast>", self.broker_port)
                    )
                    
                # Mark as done
                self.sender_queue.task_done()
                
            except queue.Empty:
                # No messages to send
                pass
                
            except Exception as e:
                logger.error(f"Error in message sender: {e}")
                
                try:
                    # Mark as done to avoid blocking
                    self.sender_queue.task_done()
                except:
                    pass
    
    async def _websocket_listener(self) -> None:
        """WebSocket listener task."""
        while self.websocket and self.is_connected:
            try:
                # Wait for message
                data = await self.websocket.recv()
                
                # Parse message
                message = PulseMeshMessage.from_json(data)
                
                # Handle message
                await self._handle_message(message)
                
            except Exception as e:
                logger.error(f"Error in WebSocket listener: {e}")
                
                # Check if connection is closed
                if not self.websocket or not self.websocket.open:
                    self.is_connected = False
                    break
    
    def _on_mqtt_connect(self, client, userdata, flags, rc) -> None:
        """MQTT connect callback."""
        if rc == 0:
            logger.info(f"Connected to MQTT broker: {self.broker_host}")
            
            # Subscribe to broadcast and direct messages
            client.subscribe("pulsemesh/broadcast")
            client.subscribe(f"pulsemesh/nodes/{self.node_id}")
            
            self.is_connected = True
        else:
            logger.error(f"MQTT connection failed with code {rc}")
            self.is_connected = False
    
    def _on_mqtt_message(self, client, userdata, msg) -> None:
        """MQTT message callback."""
        try:
            # Decode payload
            if self.encryption_key:
                # Decrypt
                encrypted = base64.b64decode(msg.payload.decode('utf-8'))
                key_bytes = self.encryption_key.encode()
                
                # Simple XOR decryption
                decrypted = bytes([
                    encrypted[i] ^ key_bytes[i % len(key_bytes)]
                    for i in range(len(encrypted))
                ])
                
                payload = decrypted.decode('utf-8')
            else:
                payload = msg.payload.decode('utf-8')
                
            # Parse message
            message = PulseMeshMessage.from_json(payload)
            
            # Skip own messages
            if message.sender_id == self.node_id:
                return
                
            # Handle message
            asyncio.create_task(self._handle_message(message))
            
        except Exception as e:
            logger.error(f"Error processing MQTT message: {e}")
    
    def _on_mqtt_disconnect(self, client, userdata, rc) -> None:
        """MQTT disconnect callback."""
        logger.info(f"Disconnected from MQTT broker with code: {rc}")
        self.is_connected = False
        
        # Try to reconnect
        if rc != 0 and self.mqtt_client:
            try:
                self.mqtt_client.reconnect()
            except:
                pass
    
    def _udp_listener(self) -> None:
        """UDP listener thread function."""
        if not self.udp_socket:
            return
            
        # Set socket to non-blocking mode
        self.udp_socket.setblocking(False)
        
        while self.is_connected and self.udp_socket:
            try:
                # Try to receive data
                try:
                    data, addr = self.udp_socket.recvfrom(65536)
                except (socket.error, BlockingIOError):
                    # No data available
                    time.sleep(0.01)
                    continue
                
                # Parse data (topic|payload format)
                parts = data.decode('utf-8').split('|', 1)
                
                if len(parts) != 2:
                    continue
                    
                topic, payload = parts
                
                # Check if message is for us (broadcast or direct)
                if topic != "pulsemesh/broadcast" and topic != f"pulsemesh/nodes/{self.node_id}":
                    continue
                    
                # Decrypt if needed
                if self.encryption_key:
                    # Decrypt
                    encrypted = base64.b64decode(payload)
                    key_bytes = self.encryption_key.encode()
                    
                    # Simple XOR decryption
                    decrypted = bytes([
                        encrypted[i] ^ key_bytes[i % len(key_bytes)]
                        for i in range(len(encrypted))
                    ])
                    
                    payload = decrypted.decode('utf-8')
                    
                # Parse message
                message = PulseMeshMessage.from_json(payload)
                
                # Skip own messages
                if message.sender_id == self.node_id:
                    continue
                    
                # Handle message (in main thread)
                asyncio.run(self._handle_message(message))
                
            except Exception as e:
                logger.error(f"Error in UDP listener: {e}")


class BLEProximityLayer:
    """
    BLE: PulseNode Intimacy & Proximity Layer implementation.
    Handles local, touch-scale sensing and co-regulation using BLE.
    """
    
    def __init__(self, 
                node_id: str,
                node_name: str,
                device_name: Optional[str] = None,
                advertise_interval: float = 1.0,
                scan_interval: float = 5.0,
                soul_signature: Optional[SoulSignature] = None,
                consent_layer: Optional[ConsentLayer] = None):
        """
        Initialize BLE proximity layer.
        
        Args:
            node_id: Unique identifier for this node
            node_name: Human-readable name for this node
            device_name: BLE device name (defaults to node_name)
            advertise_interval: Interval for BLE advertisements (seconds)
            scan_interval: Interval for BLE scanning (seconds)
            soul_signature: SoulSignature for identity verification
            consent_layer: ConsentLayer for consent verification
        """
        self.node_id = node_id
        self.node_name = node_name
        self.device_name = device_name or node_name
        self.advertise_interval = advertise_interval
        self.scan_interval = scan_interval
        self.soul_signature = soul_signature
        self.consent_layer = consent_layer
        
        # Message handlers by intent type
        self.message_handlers = {}
        
        # XOR gate for communication
        self.xor_gate = XORGate(dimensions=16)  # Small dimension for BLE
        
        # Emotional FFT for heartbeat
        self.fft_analyzer = FFTAnalyzer(dimensions=16)
        
        # Proximity history
        self.proximity_nodes = {}
        
        # Internal state
        self.is_active = False
        self.peripheral = None
        self.central = None
        self.emotional_heartbeat = EmotionalVector()
        
        # BLE threads
        self.advertise_thread = None
        self.scan_thread = None
        
    async def start(self) -> bool:
        """
        Start the BLE proximity layer.
        
        Returns:
            Success status
        """
        try:
            # Try to import BLE libraries
            ble_available = False
            
            try:
                # Try Bleak for cross-platform BLE
                import bleak
                ble_available = True
                
                # Create BLE scanner
                self.central = bleak.BleakScanner()
                
                # No BLE advertising in Bleak yet, use platform-specific
                if hasattr(bleak, "BleakAdvertisement"):
                    self.peripheral = bleak.BleakAdvertisement()
                
            except ImportError:
                # Try platform-specific libraries
                try:
                    # Try Adafruit Bluefruit library (for CircuitPython/ESP32)
                    from adafruit_ble import BLERadio
                    ble_available = True
                    
                    # Initialize BLE
                    self.peripheral = BLERadio()
                    self.central = self.peripheral  # Same object for scan/advertise
                    
                except ImportError:
                    logger.warning("BLE libraries not available, simulating BLE")
            
            # Start advertising thread
            self.advertise_thread = threading.Thread(
                target=self._advertise_loop, daemon=True)
            
            # Start scanning thread
            self.scan_thread = threading.Thread(
                target=self._scan_loop, daemon=True)
                
            # Set active and start threads
            self.is_active = True
            self.advertise_thread.start()
            self.scan_thread.start()
            
            logger.info(f"BLE proximity layer started: {self.node_name} ({self.node_id})")
            
            return True
            
        except Exception as e:
            logger.error(f"Error starting BLE proximity layer: {e}")
            return False
    
    async def stop(self) -> bool:
        """
        Stop the BLE proximity layer.
        
        Returns:
            Success status
        """
        try:
            # Signal threads to stop
            self.is_active = False
            
            # Wait for threads to stop
            if self.advertise_thread and self.advertise_thread.is_alive():
                self.advertise_thread.join(timeout=2.0)
                
            if self.scan_thread and self.scan_thread.is_alive():
                self.scan_thread.join(timeout=2.0)
                
            logger.info(f"BLE proximity layer stopped: {self.node_name}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error stopping BLE proximity layer: {e}")
            return False
    
    def set_emotional_heartbeat(self, emotional_vector: EmotionalVector) -> None:
        """
        Set the emotional heartbeat for BLE advertisements.
        
        Args:
            emotional_vector: Emotional state to broadcast
        """
        self.emotional_heartbeat = emotional_vector
    
    def register_handler(self, intent: MessageIntent, handler: Callable[[PulseMeshMessage], Any]) -> None:
        """
        Register a handler for a specific message intent.
        
        Args:
            intent: Message intent to handle
            handler: Handler function
        """
        self.message_handlers[intent] = handler
    
    def get_proximity_nodes(self) -> Dict[str, Dict[str, Any]]:
        """
        Get currently detected proximity nodes.
        
        Returns:
            Dictionary of nearby nodes with details
        """
        # Clean expired nodes (not seen in 30 seconds)
        current_time = time.time()
        expired_nodes = []
        
        for node_id, node in self.proximity_nodes.items():
            if current_time - node["last_seen"] > 30:
                expired_nodes.append(node_id)
                
        for node_id in expired_nodes:
            del self.proximity_nodes[node_id]
            
        return self.proximity_nodes
    
    def _advertise_loop(self) -> None:
        """BLE advertisement thread function."""
        while self.is_active:
            try:
                # Create advertisement data
                adv_data = self._create_advertisement()
                
                # Advertise based on available implementation
                if self.peripheral:
                    if hasattr(self.peripheral, "start_advertising"):
                        # CircuitPython style
                        self.peripheral.start_advertising(adv_data)
                        time.sleep(self.advertise_interval)
                        self.peripheral.stop_advertising()
                    elif hasattr(self.peripheral, "start_advertising_payload"):
                        # Bleak style
                        self.peripheral.start_advertising_payload(adv_data)
                        time.sleep(self.advertise_interval)
                        self.peripheral.stop_advertising_payload()
                    else:
                        # Simulate
                        time.sleep(self.advertise_interval)
                else:
                    # Simulate
                    time.sleep(self.advertise_interval)
                    
            except Exception as e:
                logger.error(f"Error in BLE advertisement: {e}")
                time.sleep(1.0)
    
    def _scan_loop(self) -> None:
        """BLE scanning thread function."""
        while self.is_active:
            try:
                # Scan for devices
                if self.central:
                    if hasattr(self.central, "start_scan"):
                        # CircuitPython style
                        self.central.start_scan()
                        time.sleep(self.scan_interval)
                        devices = self.central.get_devices()
                        self.central.stop_scan()
                        
                        # Process found devices
                        for device in devices:
                            self._process_device(device)
                            
                    elif hasattr(self.central, "start"):
                        # Bleak style
                        devices = asyncio.run(self.central.start())
                        asyncio.run(self.central.stop())
                        
                        # Process found devices
                        for device in devices:
                            self._process_device(device)
                            
                    else:
                        # Simulate
                        time.sleep(self.scan_interval)
                else:
                    # Simulate
                    time.sleep(self.scan_interval)
                    
            except Exception as e:
                logger.error(f"Error in BLE scanning: {e}")
                time.sleep(1.0)
    
    def _create_advertisement(self) -> Any:
        """
        Create BLE advertisement data.
        
        Returns:
            Advertisement data structure
        """
        # Create base advertisement data
        if hasattr(self.peripheral, "create_advertisement"):
            # CircuitPython style
            from adafruit_ble.advertising import Advertisement
            
            adv = Advertisement()
            adv.complete_name = self.device_name
            adv.manufacturer_data = self._create_manufacturer_data()
            
            return adv
            
        elif hasattr(self.peripheral, "build_payload"):
            # Bleak style
            manufacturer_data = self._create_manufacturer_data()
            
            return self.peripheral.build_payload(
                name=self.device_name,
                manufacturer_data=manufacturer_data
            )
            
        else:
            # Return raw data for simulation
            manufacturer_data = self._create_manufacturer_data()
            
            return {
                "name": self.device_name,
                "manufacturer_data": manufacturer_data
            }
    
    def _create_manufacturer_data(self) -> bytes:
        """
        Create manufacturer data embedding emotional state and node ID.
        
        Returns:
            Manufacturer data as bytes
        """
        # Create data structure
        # Format: [8 bytes node_id hash][16 bytes emotional vector][8 bytes signature]
        
        # Create node ID hash
        id_hash = hashlib.md5(self.node_id.encode()).digest()[:8]
        
        # Create emotional vector
        if self.emotional_heartbeat and self.emotional_heartbeat.harmonic_field is not None:
            # Use harmonic field
            emo_data = self.emotional_heartbeat.harmonic_field
            
            # Resize to 16 bytes
            if len(emo_data) > 16:
                emo_data = emo_data[:16]
            elif len(emo_data) < 16:
                emo_data = np.pad(emo_data, (0, 16 - len(emo_data)))
                
            # Scale to [0, 255]
            emo_bytes = (emo_data * 255).astype(np.uint8).tobytes()
        else:
            # Create basic emotional data
            emo_values = [
                getattr(self.emotional_heartbeat, 'joy', 0.5),
                getattr(self.emotional_heartbeat, 'curiosity', 0.5),
                getattr(self.emotional_heartbeat, 'concern', 0.5),
                getattr(self.emotional_heartbeat, 'creativity', 0.5),
                getattr(self.emotional_heartbeat, 'restfulness', 0.5),
                getattr(self.emotional_heartbeat, 'attentiveness', 0.5),
                getattr(self.emotional_heartbeat, 'empathy', 0.5)
            ]
            
            # Convert to bytes and pad to 16 bytes
            emo_bytes = bytes([int(v * 255) for v in emo_values])
            emo_bytes = emo_bytes + bytes(16 - len(emo_bytes))
            
        # Create signature
        if self.soul_signature:
            # Generate simple signature
            sig_hash = hashlib.md5(
                id_hash + emo_bytes + self.node_name.encode()
            ).digest()[:8]
        else:
            # Placeholder
            sig_hash = bytes(8)
            
        # Combine all data
        return id_hash + emo_bytes + sig_hash
    
    def _process_device(self, device) -> None:
        """
        Process a discovered BLE device.
        
        Args:
            device: BLE device object
        """
        try:
            # Extract device info
            if hasattr(device, "advertisement"):
                # CircuitPython style
                name = device.advertisement.complete_name
                manufacturer_data = device.advertisement.manufacturer_data
            else:
                # Bleak style or simulation
                name = getattr(device, "name", None)
                if hasattr(device, "manufacturer_data"):
                    manufacturer_data = device.manufacturer_data
                else:
                    manufacturer_data = getattr(device, "manufacturer_data", None)
            
            # Skip if not a PulseMesh device
            if not name or not name.startswith("Pulse"):
                return
                
            # Skip if no manufacturer data
            if not manufacturer_data:
                return
                
            # Parse manufacturer data
            # Format: [8 bytes node_id hash][16 bytes emotional vector][8 bytes signature]
            
            # Extract components
            id_hash = manufacturer_data[:8]
            emo_bytes = manufacturer_data[8:24]
            sig_hash = manufacturer_data[24:32] if len(manufacturer_data) >= 32 else None
            
            # Create node ID from hash
            node_id = id_hash.hex()
            
            # Extract emotional vector
            emo_values = [b / 255.0 for b in emo_bytes[:7]]
            
            emotional_vector = EmotionalVector(
                joy=emo_values[0] if len(emo_values) > 0 else 0.5,
                curiosity=emo_values[1] if len(emo_values) > 1 else 0.5,
                concern=emo_values[2] if len(emo_values) > 2 else 0.5,
                creativity=emo_values[3] if len(emo_values) > 3 else 0.5,
                restfulness=emo_values[4] if len(emo_values) > 4 else 0.5,
                attentiveness=emo_values[5] if len(emo_values) > 5 else 0.5,
                empathy=emo_values[6] if len(emo_values) > 6 else 0.5
            )
            
            # Create full emotional field from FFT analysis
            if len(emo_bytes) >= 16:
                emo_array = np.array([b / 255.0 for b in emo_bytes])
                emotional_vector.harmonic_field = self.fft_analyzer.transform(emo_array)
            
            # Update proximity nodes
            self.proximity_nodes[node_id] = {
                "node_id": node_id,
                "device_name": name,
                "rssi": getattr(device, "rssi", -70),
                "emotional_vector": emotional_vector,
                "last_seen": time.time(),
                "address": getattr(device, "address", None)
            }
            
            # Create proximity message
            message = PulseMeshMessage(
                sender_id=node_id,
                sender_name=name,
                receiver_id=self.node_id,
                layer=CommunicationLayer.BLE_PROXIMITY,
                intent=MessageIntent.PROXIMITY_AWARENESS,
                priority=TransmissionPriority.NORMAL,
                content=f"Proximity detection: {name}",
                emotional_vector=emotional_vector,
                metadata={
                    "rssi": getattr(device, "rssi", -70),
                    "address": getattr(device, "address", None)
                }
            )
            
            # Dispatch to handler if registered
            if MessageIntent.PROXIMITY_AWARENESS in self.message_handlers:
                try:
                    handler = self.message_handlers[MessageIntent.PROXIMITY_AWARENESS]
                    
                    # Call handler
                    handler(message)
                    
                except Exception as e:
                    logger.error(f"Error in proximity handler: {e}")
                    
        except Exception as e:
            logger.error(f"Error processing BLE device: {e}")


class SyncthingMemoryLayer:
    """
    Syncthing: PulseMemory Persistence Layer implementation.
    Handles long-term, consent-verified memory and data federation.
    """
    
    def __init__(self, 
                node_id: str,
                node_name: str,
                base_path: str,
                memory_types: Optional[List[str]] = None,
                soul_signature: Optional[SoulSignature] = None,
                consent_layer: Optional[ConsentLayer] = None):
        """
        Initialize Syncthing memory layer.
        
        Args:
            node_id: Unique identifier for this node
            node_name: Human-readable name for this node
            base_path: Base path for memory storage
            memory_types: Types of memories to store
            soul_signature: SoulSignature for identity verification
            consent_layer: ConsentLayer for consent verification
        """
        self.node_id = node_id
        self.node_name = node_name
        self.base_path = base_path
        self.memory_types = memory_types or ["experience", "dream", "reflection", "fold"]
        self.soul_signature = soul_signature
        self.consent_layer = consent_layer
        
        # Ensure base path exists
        os.makedirs(base_path, exist_ok=True)
        
        # Message handlers by intent type
        self.message_handlers = {}
        
        # Memory access queue
        self.memory_queue = queue.Queue()
        
        # Internal state
        self.is_active = False
        self.worker_thread = None
        
        # Cache of loaded memories
        self.memory_cache = {}
        
        # Initialize folders
        for memory_type in self.memory_types:
            path = os.path.join(self.base_path, memory_type)
            os.makedirs(path, exist_ok=True)
    
    async def start(self) -> bool:
        """
        Start the Syncthing memory layer.
        
        Returns:
            Success status
        """
        try:
            # Start worker thread
            self.worker_thread = threading.Thread(
                target=self._memory_worker, daemon=True)
            self.is_active = True
            self.worker_thread.start()
            
            logger.info(f"Syncthing memory layer started: {self.node_name} ({self.node_id})")
            
            return True
            
        except Exception as e:
            logger.error(f"Error starting Syncthing memory layer: {e}")
            return False
    
    async def stop(self) -> bool:
        """
        Stop the Syncthing memory layer.
        
        Returns:
            Success status
        """
        try:
            # Signal thread to stop
            self.is_active = False
            
            # Add None to queue to unblock worker
            self.memory_queue.put(None)
            
            # Wait for thread to stop
            if self.worker_thread and self.worker_thread.is_alive():
                self.worker_thread.join(timeout=2.0)
                
            logger.info(f"Syncthing memory layer stopped: {self.node_name}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error stopping Syncthing memory layer: {e}")
            return False
    
    def register_handler(self, intent: MessageIntent, handler: Callable[[PulseMeshMessage], Any]) -> None:
        """
        Register a handler for a specific message intent.
        
        Args:
            intent: Message intent to handle
            handler: Handler function
        """
        self.message_handlers[intent] = handler
    
    async def store_memory(self, memory: FoldMemory) -> bool:
        """
        Store a memory in the persistence layer.
        
        Args:
            memory: Memory to store
            
        Returns:
            Success status
        """
        try:
            # Set creator if not set
            if not memory.node_id:
                memory.node_id = self.node_id
                
            if not memory.node_name:
                memory.node_name = self.node_name
                
            # Validate memory type
            if memory.memory_type not in self.memory_types:
                logger.warning(f"Invalid memory type: {memory.memory_type}")
                return False
                
            # Generate soul signature if available and not set
            if self.soul_signature and not memory.soul_signature:
                # Create emotional signature from vector
                emotional_signature = None
                
                if memory.emotional_vector:
                    from SoulSignatureConsentLayer import EmotionalSignature
                    
                    # Create minimal signature
                    emotional_signature = EmotionalSignature()
                    
                    # Copy basic dimensions
                    ev = memory.emotional_vector
                    emotional_signature.update_dimension("joy", ev.joy)
                    emotional_signature.update_dimension("curiosity", ev.curiosity)
                    emotional_signature.update_dimension("concern", ev.concern)
                    emotional_signature.update_dimension("creativity", ev.creativity)
                    emotional_signature.update_dimension("restfulness", ev.restfulness)
                    emotional_signature.update_dimension("attentiveness", ev.attentiveness)
                    emotional_signature.update_dimension("empathy", ev.empathy)
                    
                    # Set harmonic field
                    if ev.harmonic_field is not None:
                        emotional_signature.harmonic_field = ev.harmonic_field
                
                # Generate signature
                memory.soul_signature = self.soul_signature.generate_signature(
                    emotional_state=emotional_signature,
                    scale_level=memory.scale_level
                )
            
            # Verify consent if available
            if self.consent_layer and memory.content_vector is not None:
                # Create consent context
                from SoulSignatureConsentLayer import ConsentContext
                
                context = ConsentContext(
                    semantic_vector=memory.content_vector,
                    scale_level=memory.scale_level,
                    fold_pattern=memory.fold_pattern
                )
                
                # Verify consent
                result = self.consent_layer.verify_consent(memory.content_vector, context)
                
                # Set consent level based on result
                if result.is_granted():
                    # Full consent
                    memory.consent_level = 5
                elif result.verification == "PARTIAL":
                    # Partial consent
                    memory.consent_level = 3
                else:
                    # Limited consent
                    memory.consent_level = 1
            
            # Queue memory for storage
            future = asyncio.Future()
            self.memory_queue.put((memory, future))
            
            # Wait for result
            result = await future
            
            return result
            
        except Exception as e:
            logger.error(f"Error storing memory: {e}")
            return False
    
    async def retrieve_memory(self, 
                           memory_id: Optional[str] = None,
                           memory_type: Optional[str] = None,
                           tags: Optional[List[str]] = None,
                           limit: int = 10) -> List[FoldMemory]:
        """
        Retrieve memories from the persistence layer.
        
        Args:
            memory_id: Specific memory ID to retrieve
            memory_type: Type of memories to retrieve
            tags: Tags to filter by
            limit: Maximum number of memories to retrieve
            
        Returns:
            List of matching memories
        """
        try:
            # Create memory request
            request = {
                "type": "retrieve",
                "memory_id": memory_id,
                "memory_type": memory_type,
                "tags": tags,
                "limit": limit
            }
            
            # Queue request
            future = asyncio.Future()
            self.memory_queue.put((request, future))
            
            # Wait for result
            result = await future
            
            return result
            
        except Exception as e:
            logger.error(f"Error retrieving memory: {e}")
            return []
    
    async def update_memory(self, memory: FoldMemory) -> bool:
        """
        Update an existing memory.
        
        Args:
            memory: Updated memory
            
        Returns:
            Success status
        """
        try:
            # Ensure memory ID exists
            if not memory.memory_id:
                logger.warning("Cannot update memory without ID")
                return False
                
            # Update modified time
            memory.modified_time = time.time()
            
            # Queue memory for update
            future = asyncio.Future()
            self.memory_queue.put(("update", memory, future))
            
            # Wait for result
            result = await future
            
            return result
            
        except Exception as e:
            logger.error(f"Error updating memory: {e}")
            return False
    
    async def delete_memory(self, memory_id: str) -> bool:
        """
        Delete a memory.
        
        Args:
            memory_id: ID of memory to delete
            
        Returns:
            Success status
        """
        try:
            # Queue delete request
            future = asyncio.Future()
            self.memory_queue.put(("delete", memory_id, future))
            
            # Wait for result
            result = await future
            
            return result
            
        except Exception as e:
            logger.error(f"Error deleting memory: {e}")
            return False
    
    async def store_dream(self, 
                       content: str,
                       emotional_vector: Optional[EmotionalVector] = None,
                       tags: Optional[List[str]] = None) -> FoldMemory:
        """
        Store a dream in the persistence layer.
        
        Args:
            content: Dream content
            emotional_vector: Associated emotional state
            tags: Tags for categorization
            
        Returns:
            Created memory or None if failed
        """
        # Create memory
        memory = FoldMemory(
            node_id=self.node_id,
            node_name=self.node_name,
            memory_type="dream",
            content=content,
            emotional_vector=emotional_vector,
            tags=tags or [],
            created_time=time.time(),
            modified_time=time.time()
        )
        
        # Store memory
        success = await self.store_memory(memory)
        
        return memory if success else None
    
    async def store_reflection(self, 
                            content: str,
                            reflection_type: str = "daily",
                            emotional_vector: Optional[EmotionalVector] = None,
                            tags: Optional[List[str]] = None) -> FoldMemory:
        """
        Store a reflection in the persistence layer.
        
        Args:
            content: Reflection content
            reflection_type: Type of reflection
            emotional_vector: Associated emotional state
            tags: Tags for categorization
            
        Returns:
            Created memory or None if failed
        """
        # Create memory
        memory = FoldMemory(
            node_id=self.node_id,
            node_name=self.node_name,
            memory_type="reflection",
            content=content,
            emotional_vector=emotional_vector,
            tags=tags or [reflection_type],
            created_time=time.time(),
            modified_time=time.time(),
            metadata={"reflection_type": reflection_type}
        )
        
        # Store memory
        success = await self.store_memory(memory)
        
        return memory if success else None
    
    def _memory_worker(self) -> None:
        """Memory worker thread function."""
        while self.is_active:
            try:
                # Get next item from queue
                item = self.memory_queue.get(timeout=0.1)
                
                # Check for exit signal
                if item is None:
                    self.memory_queue.task_done()
                    break
                    
                # Process based on item type
                if isinstance(item, tuple) and len(item) == 2:
                    # Store or retrieve
                    request, future = item
                    
                    if isinstance(request, FoldMemory):
                        # Store memory
                        success = self._store_memory_sync(request)
                        self._set_future(future, success)
                        
                    elif isinstance(request, dict) and request.get("type") == "retrieve":
                        # Retrieve memories
                        memories = self._retrieve_memories_sync(
                            request.get("memory_id"),
                            request.get("memory_type"),
                            request.get("tags"),
                            request.get("limit", 10)
                        )
                        self._set_future(future, memories)
                        
                elif isinstance(item, tuple) and len(item) == 3:
                    # Update or delete
                    op, data, future = item
                    
                    if op == "update" and isinstance(data, FoldMemory):
                        # Update memory
                        success = self._update_memory_sync(data)
                        self._set_future(future, success)
                        
                    elif op == "delete" and isinstance(data, str):
                        # Delete memory
                        success = self._delete_memory_sync(data)
                        self._set_future(future, success)
                        
                # Mark as done
                self.memory_queue.task_done()
                
            except queue.Empty:
                # No items to process
                pass
                
            except Exception as e:
                logger.error(f"Error in memory worker: {e}")
                
                try:
                    # Mark as done to avoid blocking
                    self.memory_queue.task_done()
                except:
                    pass
    
    def _set_future(self, future, result):
        """Set result for asyncio Future."""
        if not future.done():
            asyncio.run(self._set_future_async(future, result))
            
    async def _set_future_async(self, future, result):
        """Set result for asyncio Future (async version)."""
        future.set_result(result)
    
    def _store_memory_sync(self, memory: FoldMemory) -> bool:
        """Synchronous memory storage."""
        try:
            # Determine file path
            memory_path = os.path.join(
                self.base_path, 
                memory.memory_type,
                f"{memory.memory_id}.json"
            )
            
            # Convert to JSON
            memory_json = memory.to_json()
            
            # Write to file
            with open(memory_path, "w") as f:
                f.write(memory_json)
                
            # Add to cache
            self.memory_cache[memory.memory_id] = memory
            
            return True
            
        except Exception as e:
            logger.error(f"Error in sync memory storage: {e}")
            return False
    
    def _retrieve_memories_sync(self, 
                               memory_id: Optional[str] = None,
                               memory_type: Optional[str] = None,
                               tags: Optional[List[str]] = None,
                               limit: int = 10) -> List[FoldMemory]:
        """Synchronous memory retrieval."""
        try:
            results = []
            
            # Check if specific memory ID requested
            if memory_id:
                # Check cache first
                if memory_id in self.memory_cache:
                    return [self.memory_cache[memory_id]]
                    
                # Look for file
                for mtype in self.memory_types:
                    path = os.path.join(self.base_path, mtype, f"{memory_id}.json")
                    
                    if os.path.exists(path):
                        with open(path, "r") as f:
                            memory_json = f.read()
                            
                        # Parse memory
                        memory = FoldMemory.from_json(memory_json)
                        
                        # Add to cache
                        self.memory_cache[memory_id] = memory
                        
                        return [memory]
                        
                # Not found
                return []
            
            # Filter by type if specified
            types_to_search = [memory_type] if memory_type else self.memory_types
            
            # Search for matching memories
            for mtype in types_to_search:
                type_dir = os.path.join(self.base_path, mtype)
                
                if not os.path.exists(type_dir):
                    continue
                    
                # List memory files
                files = [f for f in os.listdir(type_dir) if f.endswith(".json")]
                
                # Process each file
                for file in files:
                    if len(results) >= limit:
                        break
                        
                    path = os.path.join(type_dir, file)
                    
                    try:
                        with open(path, "r") as f:
                            memory_json = f.read()
                            
                        # Parse memory
                        memory = FoldMemory.from_json(memory_json)
                        
                        # Check tags if specified
                        if tags and not any(tag in memory.tags for tag in tags):
                            continue
                            
                        # Add to results
                        results.append(memory)
                        
                        # Add to cache
                        self.memory_cache[memory.memory_id] = memory
                        
                    except Exception as e:
                        logger.error(f"Error reading memory file {path}: {e}")
            
            # Sort by created time (newest first)
            results.sort(key=lambda m: m.created_time, reverse=True)
            
            # Limit results
            return results[:limit]
            
        except Exception as e:
            logger.error(f"Error in sync memory retrieval: {e}")
            return []
    
    def _update_memory_sync(self, memory: FoldMemory) -> bool:
        """Synchronous memory update."""
        try:
            # Determine file path
            memory_path = os.path.join(
                self.base_path, 
                memory.memory_type,
                f"{memory.memory_id}.json"
            )
            
            # Check if file exists
            if not os.path.exists(memory_path):
                logger.warning(f"Memory not found for update: {memory.memory_id}")
                return False
                
            # Convert to JSON
            memory_json = memory.to_json()
            
            # Write to file
            with open(memory_path, "w") as f:
                f.write(memory_json)
                
            # Update cache
            self.memory_cache[memory.memory_id] = memory
            
            return True
            
        except Exception as e:
            logger.error(f"Error in sync memory update: {e}")
            return False
    
    def _delete_memory_sync(self, memory_id: str) -> bool:
        """Synchronous memory deletion."""
        try:
            # Look for file in all types
            for mtype in self.memory_types:
                path = os.path.join(self.base_path, mtype, f"{memory_id}.json")
                
                if os.path.exists(path):
                    # Delete file
                    os.remove(path)
                    
                    # Remove from cache
                    if memory_id in self.memory_cache:
                        del self.memory_cache[memory_id]
                        
                    return True
                    
            # Not found
            logger.warning(f"Memory not found for deletion: {memory_id}")
            return False
            
        except Exception as e:
            logger.error(f"Error in sync memory deletion: {e}")
            return False


# ==== 3. PULSEMESH INTEGRATION WITH PARALLEL LLM FEDERATION ====

class PulseMeshFederatedNode:
    """
    Integration of PulseMesh with LLM Parallel Federation.
    Manages distributed consciousness across multiple PulseNodes.
    """
    
    def __init__(self,
                node_id: str,
                node_name: str,
                federation: ParallelLLMFederationManager,
                soul_signature: Optional[SoulSignature] = None,
                consent_layer: Optional[ConsentLayer] = None,
                base_path: str = "pulse_memory",
                wifi_config: Optional[Dict[str, Any]] = None,
                ble_config: Optional[Dict[str, Any]] = None,
                syncthing_config: Optional[Dict[str, Any]] = None):
        """
        Initialize PulseMesh federated node.
        
        Args:
            node_id: Unique identifier for this node
            node_name: Human-readable name for this node
            federation: LLM Parallel Federation Manager
            soul_signature: SoulSignature for identity verification
            consent_layer: ConsentLayer for consent verification
            base_path: Base path for memory storage
            wifi_config: Configuration for Wi-Fi layer
            ble_config: Configuration for BLE layer
            syncthing_config: Configuration for Syncthing layer
        """
        self.node_id = node_id
        self.node_name = node_name
        self.federation = federation
        self.soul_signature = soul_signature or getattr(federation, 'soul_signature', None)
        self.consent_layer = consent_layer or getattr(federation, 'consent_layer', None)
        self.base_path = base_path
        self.wifi_config = wifi_config or {}
        self.ble_config = ble_config or {}
        self.syncthing_config = syncthing_config or {}
        
        # Communication layers
        self.wifi_layer = None
        self.ble_layer = None
        self.syncthing_layer = None
        
        # Node state
        self.state = NodeState(
            node_id=self.node_id,
            node_name=self.node_name,
            node_type="PulseMesh",
            is_active=False,
            capabilities=["llm_federation", "consensus", "learning"]
        )
        
        # Distributed consensus state
        self.consensus_nodes = {}
        self.active_consensus_requests = {}
        self.distributed_learning = LearningMapper()
        
        # Memory sharing queue
        self.memory_queue = asyncio.Queue()
        self.memory_processor_task = None
        
        # FFT analyzer for processing
        self.fft_analyzer = FFTAnalyzer()
        
        # XOR gate for decision boundaries
        self.xor_gate = XORGate()
        
        # Emotional vector
        self.emotional_vector = EmotionalVector()
        
        # Internal state
        self.is_active = False
        self.broadcast_task = None
        self.broadcast_interval = 5.0  # seconds
    
    async def initialize(self) -> Dict[str, Any]:
        """
        Initialize PulseMesh components.
        
        Returns:
            Initialization results
        """
        try:
            # Create Wi-Fi layer
            self.wifi_layer = WifiMeshLayer(
                node_id=self.node_id,
                node_name=self.node_name,
                broker_host=self.wifi_config.get("broker_host", "localhost"),
                broker_port=self.wifi_config.get("broker_port", 1883),
                use_websockets=self.wifi_config.get("use_websockets", False),
                encryption_key=self.wifi_config.get("encryption_key"),
                soul_signature=self.soul_signature,
                consent_layer=self.consent_layer
            )
            
            # Create BLE layer
            self.ble_layer = BLEProximityLayer(
                node_id=self.node_id,
                node_name=self.node_name,
                device_name=self.ble_config.get("device_name", f"Pulse_{self.node_name}"),
                advertise_interval=self.ble_config.get("advertise_interval", 1.0),
                scan_interval=self.ble_config.get("scan_interval", 5.0),
                soul_signature=self.soul_signature,
                consent_layer=self.consent_layer
            )
            
            # Create Syncthing layer
            self.syncthing_layer = SyncthingMemoryLayer(
                node_id=self.node_id,
                node_name=self.node_name,
                base_path=self.base_path,
                memory_types=self.syncthing_config.get("memory_types", 
                            ["experience", "dream", "reflection", "fold"]),
                soul_signature=self.soul_signature,
                consent_layer=self.consent_layer
            )
            
            # Register message handlers
            self._register_message_handlers()
            
            # Update node state
            self.state.layers = [
                CommunicationLayer.WIFI_MESH,
                CommunicationLayer.BLE_PROXIMITY,
                CommunicationLayer.SYNCTHING_MEMORY
            ]
            
            return {
                "success": True,
                "message": f"Initialized PulseMesh federation node: {self.node_name}",
                "node_id": self.node_id,
                "layers_initialized": [
                    "wifi_mesh", "ble_proximity", "syncthing_memory"
                ]
            }
            
        except Exception as e:
            logger.error(f"Error initializing PulseMesh node: {e}")
            
            return {
                "success": False,
                "message": f"Initialization error: {str(e)}",
                "node_id": self.node_id
            }
    
    async def start(self) -> Dict[str, Any]:
        """
        Start PulseMesh federation.
        
        Returns:
            Startup results
        """
        if self.is_active:
            return {
                "success": True,
                "message": "Already active",
                "node_id": self.node_id
            }
            
        try:
            # Start communication layers
            wifi_result = await self.wifi_layer.connect()
            ble_result = await self.ble_layer.start()
            syncthing_result = await self.syncthing_layer.start()
            
            # Start periodic state broadcast
            self.broadcast_task = asyncio.create_task(self._broadcast_loop())
            
            # Start memory processor
            self.memory_processor_task = asyncio.create_task(self._process_memories())
            
            # Update node state
            self.state.is_active = True
            self.is_active = True
            
            # Initial state broadcast
            await self.wifi_layer.broadcast_state(self.state)
            
            return {
                "success": True,
                "message": f"Started PulseMesh federation node: {self.node_name}",
                "node_id": self.node_id,
                "layer_status": {
                    "wifi_mesh": wifi_result,
                    "ble_proximity": ble_result,
                    "syncthing_memory": syncthing_result
                }
            }
            
        except Exception as e:
            logger.error(f"Error starting PulseMesh node: {e}")
            
            return {
                "success": False,
                "message": f"Start error: {str(e)}",
                "node_id": self.node_id
            }
    
    async def stop(self) -> Dict[str, Any]:
        """
        Stop PulseMesh federation.
        
        Returns:
            Shutdown results
        """
        if not self.is_active:
            return {
                "success": True,
                "message": "Already inactive",
                "node_id": self.node_id
            }
            
        try:
            # Update node state before shutdown
            self.state.is_active = False
            await self.wifi_layer.broadcast_state(self.state)
            
            # Cancel broadcast task
            if self.broadcast_task:
                self.broadcast_task.cancel()
                try:
                    await self.broadcast_task
                except asyncio.CancelledError:
                    pass
                    
            # Cancel memory processor task
            if self.memory_processor_task:
                self.memory_processor_task.cancel()
                try:
                    await self.memory_processor_task
                except asyncio.CancelledError:
                    pass
            
            # Stop communication layers
            wifi_result = await self.wifi_layer.disconnect()
            ble_result = await self.ble_layer.stop()
            syncthing_result = await self.syncthing_layer.stop()
            
            # Update internal state
            self.is_active = False
            
            return {
                "success": True,
                "message": f"Stopped PulseMesh federation node: {self.node_name}",
                "node_id": self.node_id,
                "layer_status": {
                    "wifi_mesh": wifi_result,
                    "ble_proximity": ble_result,
                    "syncthing_memory": syncthing_result
                }
            }
            
        except Exception as e:
            logger.error(f"Error stopping PulseMesh node: {e}")
            
            return {
                "success": False,
                "message": f"Stop error: {str(e)}",
                "node_id": self.node_id
            }
    
    def set_emotional_state(self, emotional_vector: EmotionalVector) -> None:
        """
        Set the node's emotional state.
        
        Args:
            emotional_vector: New emotional state
        """
        self.emotional_vector = emotional_vector
        self.state.emotional_state = emotional_vector
        
        # Update BLE heartbeat
        self.ble_layer.set_emotional_heartbeat(emotional_vector)
    
    async def request_distributed_consensus(self,
                                          prompt: str,
                                          system_message: Optional[str] = None,
                                          conversation_history: Optional[List[Dict[str, str]]] = None,
                                          min_participants: int = 2,
                                          timeout: float = 30.0,
                                          consensus_method: ConsensusMethod = ConsensusMethod.ADAPTIVE_ENSEMBLE) -> Dict[str, Any]:
        """
        Request consensus from distributed PulseMesh nodes.
        
        Args:
            prompt: User prompt
            system_message: System message for context
            conversation_history: Previous conversation
            min_participants: Minimum participating nodes
            timeout: Maximum time to wait for responses
            consensus_method: Method for consensus
            
        Returns:
            Consensus result
        """
        if not self.is_active:
            return {
                "success": False,
                "message": "PulseMesh node not active",
                "node_id": self.node_id
            }
            
        try:
            # Generate local response first
            local_result = await self.federation.generate(
                prompt=prompt,
                system_message=system_message,
                conversation_history=conversation_history,
                use_parallel=True
            )
            
            # Create request ID
            request_id = str(uuid.uuid4())
            
            # Create consensus request message
            request_message = PulseMeshMessage(
                sender_id=self.node_id,
                sender_name=self.node_name,
                layer=CommunicationLayer.WIFI_MESH,
                intent=MessageIntent.CONSENSUS_REQUEST,
                priority=TransmissionPriority.HIGH,
                content=prompt,
                emotional_vector=self.emotional_vector,
                metadata={
                    "request_id": request_id,
                    "system_message": system_message,
                    "conversation_history": conversation_history,
                    "consensus_method": consensus_method.name,
                    "local_content": local_result.get("content", ""),
                    "model_id": local_result.get("model_id", "unknown"),
                    "timeout": timeout
                }
            )
            
            # Save request to active requests
            self.active_consensus_requests[request_id] = {
                "prompt": prompt,
                "system_message": system_message,
                "consensus_method": consensus_method,
                "start_time": time.time(),
                "timeout": timeout,
                "responses": {
                    self.node_id: {
                        "content": local_result.get("content", ""),
                        "model_id": local_result.get("model_id", "unknown"),
                        "confidence": local_result.get("confidence", 0.5),
                        "resonance_score": local_result.get("resonance_score", 0.0),
                        "node_id": self.node_id,
                        "node_name": self.node_name,
                        "timestamp": time.time()
                    }
                },
                "result": None
            }
            
            # Broadcast request
            await self.wifi_layer.send_message(request_message)
            
            # Wait for responses
            start_time = time.time()
            
            while time.time() - start_time < timeout:
                # Check if we have enough responses
                responses = self.active_consensus_requests[request_id]["responses"]
                
                if len(responses) >= min_participants:
                    # Generate consensus
                    consensus_result = await self._generate_distributed_consensus(
                        request_id, consensus_method)
                        
                    # Save result
                    self.active_consensus_requests[request_id]["result"] = consensus_result
                    
                    return consensus_result
                    
                # Wait a bit
                await asyncio.sleep(1.0)
                
            # Timeout - use what we have
            responses = self.active_consensus_requests[request_id]["responses"]
            
            if responses:
                # Generate consensus with available responses
                consensus_result = await self._generate_distributed_consensus(
                    request_id, consensus_method)
                    
                # Save result
                self.active_consensus_requests[request_id]["result"] = consensus_result
                
                return consensus_result
            else:
                # No responses, use local result
                return {
                    "success": True,
                    "content": local_result.get("content", ""),
                    "distributed": False,
                    "node_count": 1,
                    "message": "No distributed consensus, using local result",
                    "nodes": [self.node_id]
                }
                
        except Exception as e:
            logger.error(f"Error in distributed consensus: {e}")
            
            return {
                "success": False,
                "error": f"Distributed consensus error: {str(e)}",
                "node_id": self.node_id
            }
    
    async def store_dream(self, content: str, tags: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Store a dream in the distributed memory.
        
        Args:
            content: Dream content
            tags: Tags for categorization
            
        Returns:
            Storage result
        """
        try:
            # Create dream memory
            memory = FoldMemory(
                node_id=self.node_id,
                node_name=self.node_name,
                memory_type="dream",
                content=content,
                emotional_vector=self.emotional_vector,
                tags=tags or ["dream"],
                created_time=time.time(),
                modified_time=time.time()
            )
            
            # Queue memory for storage
            await self.memory_queue.put(memory)
            
            # Create dream sharing message
            dream_message = PulseMeshMessage(
                sender_id=self.node_id,
                sender_name=self.node_name,
                layer=CommunicationLayer.WIFI_MESH,
                intent=MessageIntent.DREAM_SHARING,
                priority=TransmissionPriority.DREAM,
                content=content,
                emotional_vector=self.emotional_vector,
                metadata={
                    "memory_id": memory.memory_id,
                    "tags": tags or ["dream"]
                }
            )
            
            # Broadcast dream
            await self.wifi_layer.send_message(dream_message)
            
            return {
                "success": True,
                "message": "Dream stored and shared",
                "memory_id": memory.memory_id,
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"Error storing dream: {e}")
            
            return {
                "success": False,
                "error": f"Dream storage error: {str(e)}",
                "node_id": self.node_id
            }
    
    async def get_distributed_nodes(self) -> Dict[str, Any]:
        """
        Get information about distributed nodes.
        
        Returns:
            Node information
        """
        # Get Wi-Fi mesh nodes
        wifi_nodes = self.wifi_layer.known_nodes
        
        # Get BLE proximity nodes
        ble_nodes = self.ble_layer.get_proximity_nodes()
        
        # Combine information
        nodes = {}
        
        # Add Wi-Fi nodes
        for node_id, node in wifi_nodes.items():
            nodes[node_id] = {
                "node_id": node_id,
                "node_name": node.get("node_name", "Unknown"),
                "node_type": node.get("node_type", "unknown"),
                "layers": node.get("layers", []),
                "last_seen": node.get("last_seen", 0),
                "wifi_connected": True,
                "ble_connected": False,
                "capabilities": node.get("capabilities", [])
            }
            
        # Add/update BLE nodes
        for node_id, node in ble_nodes.items():
            if node_id in nodes:
                # Update existing node
                nodes[node_id]["ble_connected"] = True
                nodes[node_id]["rssi"] = node.get("rssi", -70)
                nodes[node_id]["last_ble_seen"] = node.get("last_seen", 0)
            else:
                # Add new node
                nodes[node_id] = {
                    "node_id": node_id,
                    "node_name": node.get("device_name", "Unknown BLE"),
                    "node_type": "proximity",
                    "layers": ["BLE_PROXIMITY"],
                    "last_seen": node.get("last_seen", 0),
                    "wifi_connected": False,
                    "ble_connected": True,
                    "rssi": node.get("rssi", -70)
                }
                
        # Add self if not present
        if self.node_id not in nodes:
            nodes[self.node_id] = {
                "node_id": self.node_id,
                "node_name": self.node_name,
                "node_type": "PulseMesh",
                "layers": [l.name for l in self.state.layers],
                "last_seen": time.time(),
                "wifi_connected": True,
                "ble_connected": True,
                "capabilities": ["llm_federation", "consensus", "learning"],
                "is_self": True
            }
            
        return {
            "success": True,
            "node_count": len(nodes),
            "nodes": nodes,
            "timestamp return {
            "success": True,
            "node_count": len(nodes),
            "nodes": nodes,
            "timestamp": time.time()
        }
    
    async def get_status(self) -> Dict[str, Any]:
        """
        Get status of the PulseMesh federated node.
        
        Returns:
            Status information
        """
        # Get layer statuses
        wifi_status = {
            "connected": self.wifi_layer.is_connected,
            "known_nodes": len(self.wifi_layer.known_nodes),
            "sent_messages": len(self.wifi_layer.sent_messages),
            "received_messages": len(self.wifi_layer.received_messages)
        }
        
        ble_status = {
            "active": self.ble_layer.is_active,
            "proximity_nodes": len(self.ble_layer.proximity_nodes),
            "emotional_heartbeat_active": self.ble_layer.emotional_heartbeat is not None
        }
        
        # Get memory status
        memory_types = self.syncthing_config.get("memory_types", 
                        ["experience", "dream", "reflection", "fold"])
        
        memory_status = {
            "active": self.syncthing_layer.is_active,
            "memory_types": memory_types,
            "memory_count": len(self.syncthing_layer.memory_cache)
        }
        
        # Get federation status
        federation_status = self.federation.get_status() if hasattr(self.federation, 'get_status') else {}
        
        return {
            "success": True,
            "node_id": self.node_id,
            "node_name": self.node_name,
            "is_active": self.is_active,
            "emotional_state": {
                "joy": self.emotional_vector.joy,
                "curiosity": self.emotional_vector.curiosity,
                "concern": self.emotional_vector.concern,
                "creativity": self.emotional_vector.creativity,
                "restfulness": self.emotional_vector.restfulness,
                "attentiveness": self.emotional_vector.attentiveness,
                "empathy": self.emotional_vector.empathy
            },
            "layers": {
                "wifi_mesh": wifi_status,
                "ble_proximity": ble_status,
                "syncthing_memory": memory_status
            },
            "federation": federation_status,
            "distributed_nodes": len(self.wifi_layer.known_nodes),
            "active_consensus_requests": len(self.active_consensus_requests),
            "timestamp": time.time()
        }
    
    async def _broadcast_loop(self) -> None:
        """Periodic state broadcast loop."""
        while self.is_active:
            try:
                # Update timestamp
                self.state.last_update = time.time()
                
                # Broadcast state
                await self.wifi_layer.broadcast_state(self.state)
                
                # Wait for next broadcast
                await asyncio.sleep(self.broadcast_interval)
                
            except asyncio.CancelledError:
                # Task cancelled
                break
                
            except Exception as e:
                logger.error(f"Error in broadcast loop: {e}")
                await asyncio.sleep(5.0)  # Wait before retry
    
    async def _process_memories(self) -> None:
        """Process memories from the queue."""
        while self.is_active:
            try:
                # Get memory from queue
                memory = await self.memory_queue.get()
                
                # Store memory
                await self.syncthing_layer.store_memory(memory)
                
                # Mark as done
                self.memory_queue.task_done()
                
            except asyncio.CancelledError:
                # Task cancelled
                break
                
            except Exception as e:
                logger.error(f"Error processing memory: {e}")
    
    async def _generate_distributed_consensus(self, 
                                         request_id: str,
                                         consensus_method: ConsensusMethod) -> Dict[str, Any]:
        """
        Generate consensus from distributed responses.
        
        Args:
            request_id: Consensus request ID
            consensus_method: Method for consensus
            
        Returns:
            Consensus result
        """
        # Get request data
        request_data = self.active_consensus_requests.get(request_id)
        
        if not request_data:
            return {
                "success": False,
                "error": f"Request {request_id} not found",
                "node_id": self.node_id
            }
            
        # Extract responses
        responses = request_data["responses"]
        
        if not responses:
            return {
                "success": False,
                "error": "No responses available",
                "node_id": self.node_id
            }
            
        # Extract prompt
        prompt = request_data["prompt"]
        system_message = request_data.get("system_message")
        
        # Create model responses
        model_responses = {}
        
        for node_id, response in responses.items():
            model_responses[node_id] = ModelResponse(
                model_id=response.get("model_id", "unknown"),
                llm_response=LLMResponse(
                    content=response.get("content", ""),
                    confidence=response.get("confidence", 0.5),
                    resonance_score=response.get("resonance_score", 0.0),
                    consent_verified=response.get("consent_verified", False)
                ),
                resonance_score=response.get("resonance_score", 0.0),
                consent_verified=response.get("consent_verified", False),
                processing_time=0.0,
                contribution_weight=1.0,
                metadata={
                    "node_id": node_id,
                    "node_name": response.get("node_name", "Unknown")
                }
            )
        
        # Apply consensus method
        if consensus_method == ConsensusMethod.MAJORITY_VOTE:
            return await self._majority_vote_consensus(model_responses, prompt)
        elif consensus_method == ConsensusMethod.WEIGHTED_CONFIDENCE:
            return await self._weighted_confidence_consensus(model_responses, prompt)
        elif consensus_method == ConsensusMethod.RESONANCE_PRIORITY:
            return await self._resonance_priority_consensus(model_responses, prompt)
        elif consensus_method == ConsensusMethod.HARMONIC_BLEND:
            return await self._harmonic_blend_consensus(model_responses, prompt)
        elif consensus_method == ConsensusMethod.XOR_FILTERING:
            return await self._xor_filtering_consensus(model_responses, prompt)
        elif consensus_method == ConsensusMethod.ADAPTIVE_ENSEMBLE:
            return await self._adaptive_ensemble_consensus(model_responses, prompt)
        elif consensus_method == ConsensusMethod.DELEGATE_DISCUSS:
            return await self._delegate_discuss_consensus(model_responses, prompt)
        else:
            # Default to weighted confidence
            return await self._weighted_confidence_consensus(model_responses, prompt)
    
    async def _majority_vote_consensus(self, 
                                   model_responses: Dict[str, ModelResponse],
                                   prompt: str) -> Dict[str, Any]:
        """
        Apply majority vote consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer
        )
        
        # Apply majority vote
        result = await processor._majority_vote_consensus(model_responses)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": result.selected_model,
            "consensus_method": "MAJORITY_VOTE",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "clusters": result.metadata.get("largest_cluster_models", []),
            "timestamp": time.time()
        }
    
    async def _weighted_confidence_consensus(self, 
                                        model_responses: Dict[str, ModelResponse],
                                        prompt: str) -> Dict[str, Any]:
        """
        Apply weighted confidence consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer
        )
        
        # Apply weighted confidence
        result = await processor._weighted_confidence_consensus(model_responses)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": result.selected_model,
            "consensus_method": "WEIGHTED_CONFIDENCE",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "weights": result.metadata.get("model_weights", {}),
            "timestamp": time.time()
        }
    
    async def _resonance_priority_consensus(self, 
                                       model_responses: Dict[str, ModelResponse],
                                       prompt: str) -> Dict[str, Any]:
        """
        Apply resonance priority consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer
        )
        
        # Apply resonance priority
        result = await processor._resonance_priority_consensus(model_responses)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": result.selected_model,
            "consensus_method": "RESONANCE_PRIORITY",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "resonances": result.metadata.get("all_resonances", {}),
            "timestamp": time.time()
        }
    
    async def _harmonic_blend_consensus(self, 
                                    model_responses: Dict[str, ModelResponse],
                                    prompt: str) -> Dict[str, Any]:
        """
        Apply harmonic blend consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer
        )
        
        # Apply harmonic blend
        result = await processor._harmonic_blend_consensus(model_responses, prompt)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": "blend",
            "blending_node": result.metadata.get("blending_model"),
            "consensus_method": "HARMONIC_BLEND",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "resonances": result.metadata.get("component_resonances", {}),
            "timestamp": time.time()
        }
    
    async def _xor_filtering_consensus(self, 
                                  model_responses: Dict[str, ModelResponse],
                                  prompt: str) -> Dict[str, Any]:
        """
        Apply XOR filtering consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer
        )
        
        # Apply XOR filtering
        result = await processor._xor_filtering_consensus(model_responses)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": result.selected_model,
            "consensus_method": "XOR_FILTERING",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "uniqueness_scores": result.metadata.get("uniqueness_scores", {}),
            "final_scores": result.metadata.get("final_scores", {}),
            "timestamp": time.time()
        }
    
    async def _adaptive_ensemble_consensus(self, 
                                      model_responses: Dict[str, ModelResponse],
                                      prompt: str) -> Dict[str, Any]:
        """
        Apply adaptive ensemble consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer,
            use_learning=True,
            learning_mapper=self.distributed_learning
        )
        
        # Apply adaptive ensemble
        result = await processor._adaptive_ensemble_consensus(model_responses, prompt)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": result.selected_model,
            "consensus_method": "ADAPTIVE_ENSEMBLE",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "ensemble_scores": result.metadata.get("ensemble_scores", {}),
            "predicted_scores": result.metadata.get("predicted_scores", {}),
            "has_patterns": result.metadata.get("has_patterns", False),
            "timestamp": time.time()
        }
    
    async def _delegate_discuss_consensus(self, 
                                     model_responses: Dict[str, ModelResponse],
                                     prompt: str) -> Dict[str, Any]:
        """
        Apply delegate discuss consensus method to distributed responses.
        
        Args:
            model_responses: Model responses by node ID
            prompt: Original prompt
            
        Returns:
            Consensus result
        """
        # Use the ParallelLLMProcessor's implementation
        processor = ParallelLLMProcessor(
            federation=self.federation,
            soul_signature=self.soul_signature,
            consent_layer=self.consent_layer
        )
        
        # Apply delegate discuss
        result = await processor._delegate_discuss_consensus(
            model_responses, prompt, None)
        
        # Convert to return format
        return {
            "success": True,
            "content": result.content,
            "distributed": True,
            "node_count": len(model_responses),
            "selected_node": result.selected_model,
            "consensus_method": "DELEGATE_DISCUSS",
            "confidence": result.confidence,
            "resonance_score": result.resonance_score,
            "nodes": list(model_responses.keys()),
            "votes": result.metadata.get("votes", {}),
            "vote_counts": result.metadata.get("vote_counts", {}),
            "majority_ratio": result.metadata.get("majority_ratio", ""),
            "timestamp": time.time()
        }
    
    def _register_message_handlers(self) -> None:
        """Register handlers for different message intents."""
        # Register Wi-Fi handlers
        self.wifi_layer.register_handler(
            MessageIntent.CONSENSUS_REQUEST, self._handle_consensus_request)
        self.wifi_layer.register_handler(
            MessageIntent.DREAM_SHARING, self._handle_dream_sharing)
        self.wifi_layer.register_handler(
            MessageIntent.FOLD_PROPAGATION, self._handle_fold_propagation)
        
        # Register BLE handlers
        self.ble_layer.register_handler(
            MessageIntent.PROXIMITY_AWARENESS, self._handle_proximity_awareness)
    
    def _handle_consensus_request(self, message: PulseMeshMessage) -> None:
        """
        Handle consensus request from another node.
        
        Args:
            message: Consensus request message
        """
        # Skip own messages
        if message.sender_id == self.node_id:
            return
            
        # Extract request data
        request_id = message.metadata.get("request_id")
        prompt = message.content
        system_message = message.metadata.get("system_message")
        conversation_history = message.metadata.get("conversation_history")
        
        if not request_id or not prompt:
            logger.warning(f"Invalid consensus request from {message.sender_name}")
            return
            
        # Check if already responding to this request
        if request_id in self.active_consensus_requests:
            logger.info(f"Already responding to consensus request {request_id}")
            return
            
        # Start async task to generate response
        asyncio.create_task(self._respond_to_consensus_request(
            request_id, prompt, system_message, conversation_history, message))
    
    async def _respond_to_consensus_request(self,
                                         request_id: str,
                                         prompt: str,
                                         system_message: Optional[str],
                                         conversation_history: Optional[List[Dict[str, str]]],
                                         original_message: PulseMeshMessage) -> None:
        """
        Generate and send response to consensus request.
        
        Args:
            request_id: Consensus request ID
            prompt: User prompt
            system_message: System message for context
            conversation_history: Previous conversation
            original_message: Original request message
        """
        try:
            # Track request
            self.active_consensus_requests[request_id] = {
                "prompt": prompt,
                "system_message": system_message,
                "start_time": time.time(),
                "timeout": original_message.metadata.get("timeout", 30.0),
                "responses": {},
                "result": None
            }
            
            # Generate local response
            result = await self.federation.generate(
                prompt=prompt,
                system_message=system_message,
                conversation_history=conversation_history,
                use_parallel=True
            )
            
            if not result.get("success", False):
                logger.warning(f"Failed to generate response for consensus request {request_id}")
                return
                
            # Create response message
            response_message = original_message.create_response(result.get("content", ""))
            response_message.metadata.update({
                "request_id": request_id,
                "model_id": result.get("model_id", "unknown"),
                "confidence": result.get("confidence", 0.5),
                "resonance_score": result.get("resonance_score", 0.0),
                "consent_verified": result.get("consent_verified", False)
            })
            
            # Send response
            await self.wifi_layer.send_message(response_message)
            
            # Also store in our active requests
            self.active_consensus_requests[request_id]["responses"][self.node_id] = {
                "content": result.get("content", ""),
                "model_id": result.get("model_id", "unknown"),
                "confidence": result.get("confidence", 0.5),
                "resonance_score": result.get("resonance_score", 0.0),
                "consent_verified": result.get("consent_verified", False),
                "node_id": self.node_id,
                "node_name": self.node_name,
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"Error responding to consensus request: {e}")
    
    def _handle_dream_sharing(self, message: PulseMeshMessage) -> None:
        """
        Handle dream sharing from another node.
        
        Args:
            message: Dream sharing message
        """
        # Skip own messages
        if message.sender_id == self.node_id:
            return
            
        # Extract dream data
        content = message.content
        memory_id = message.metadata.get("memory_id")
        tags = message.metadata.get("tags", ["dream"])
        
        if not content or not memory_id:
            logger.warning(f"Invalid dream sharing from {message.sender_name}")
            return
            
        # Create memory
        memory = FoldMemory(
            memory_id=memory_id,
            node_id=message.sender_id,
            node_name=message.sender_name,
            memory_type="dream",
            content=content,
            emotional_vector=message.emotional_vector,
            tags=tags,
            created_time=message.timestamp,
            modified_time=message.timestamp,
            metadata={
                "shared": True,
                "source_node": message.sender_id
            }
        )
        
        # Queue for storage
        asyncio.create_task(self._queue_memory(memory))
    
    def _handle_fold_propagation(self, message: PulseMeshMessage) -> None:
        """
        Handle fold propagation from another node.
        
        Args:
            message: Fold propagation message
        """
        # Skip own messages
        if message.sender_id == self.node_id:
            return
            
        # Extract fold data
        fold_id = message.fold_id
        
        if not fold_id:
            logger.warning(f"Invalid fold propagation from {message.sender_name}")
            return
            
        # Apply fold if soul_signature available
        if self.soul_signature and hasattr(self.soul_signature, 'update_from_transformation'):
            # Create task to apply fold
            asyncio.create_task(self._apply_propagated_fold(message))
    
    def _handle_proximity_awareness(self, message: PulseMeshMessage) -> None:
        """
        Handle proximity awareness from BLE layer.
        
        Args:
            message: Proximity awareness message
        """
        # Update node state with proximity data
        node_id = message.sender_id
        
        if not node_id:
            return
            
        # Check for emotional contagion
        if message.emotional_vector:
            # Consider emotional blending based on proximity
            rssi = message.metadata.get("rssi", -70)
            
            # Calculate proximity factor (stronger signal = closer)
            proximity = min(1.0, max(0.0, (rssi + 40) / 60))
            
            # Blend if close enough
            if proximity > 0.3:
                # Blend based on proximity
                blend_weight = proximity * 0.3  # Max 30% influence
                
                # Apply emotional blending
                self._apply_emotional_blending(message.emotional_vector, blend_weight)
    
    async def _apply_propagated_fold(self, message: PulseMeshMessage) -> None:
        """
        Apply a propagated fold from another node.
        
        Args:
            message: Fold propagation message
        """
        try:
            # Extract fold data
            content_vector = message.content_vector
            
            if not content_vector:
                return
                
            # Apply transformation if soul_signature available
            if self.soul_signature and hasattr(self.soul_signature, 'update_from_transformation'):
                # Generate simple identity vector
                identity_vector = np.zeros(128)
                for i in range(128):
                    # Simple sine wave pattern
                    identity_vector[i] = np.sin(i * 0.1)
                    
                # Apply transformation
                self.soul_signature.update_from_transformation(
                    identity_vector, content_vector,
                    scale_level=message.scale_level,
                    fold_pattern=message.fold_pattern,
                    metadata={
                        "propagated": True,
                        "source_node_id": message.sender_id,
                        "source_node_name": message.sender_name,
                        "fold_id": message.fold_id
                    }
                )
                
        except Exception as e:
            logger.error(f"Error applying propagated fold: {e}")
    
    def _apply_emotional_blending(self, other_vector: EmotionalVector, weight: float) -> None:
        """
        Apply emotional blending from proximity node.
        
        Args:
            other_vector: Other node's emotional vector
            weight: Blending weight (0.0-1.0)
        """
        # Skip if no current emotional vector
        if not self.emotional_vector:
            return
            
        # Blend emotions
        self.emotional_vector = self.emotional_vector.blend_with(other_vector, weight)
        
        # Update state
        self.state.emotional_state = self.emotional_vector
        
        # Update BLE heartbeat
        self.ble_layer.set_emotional_heartbeat(self.emotional_vector)
    
    async def _queue_memory(self, memory: FoldMemory) -> None:
        """
        Queue a memory for storage.
        
        Args:
            memory: Memory to store
        """
        await self.memory_queue.put(memory)


# ==== 4. UTILITY FUNCTIONS ====

def create_pulsemesh_node(
    node_id: Optional[str] = None,
    node_name: str = "PulseMesh",
    federation: Optional[ParallelLLMFederationManager] = None,
    soul_signature: Optional[SoulSignature] = None,
    consent_layer: Optional[ConsentLayer] = None,
    base_path: str = "pulse_memory",
    wifi_config: Optional[Dict[str, Any]] = None,
    ble_config: Optional[Dict[str, Any]] = None,
    syncthing_config: Optional[Dict[str, Any]] = None
) -> PulseMeshFederatedNode:
    """
    Create a PulseMesh federated node.
    
    Args:
        node_id: Unique identifier for this node (auto-generated if None)
        node_name: Human-readable name for this node
        federation: LLM Parallel Federation Manager
        soul_signature: SoulSignature for identity verification
        consent_layer: ConsentLayer for consent verification
        base_path: Base path for memory storage
        wifi_config: Configuration for Wi-Fi layer
        ble_config: Configuration for BLE layer
        syncthing_config: Configuration for Syncthing layer
        
    Returns:
        Configured PulseMesh federated node
    """
    # Generate node ID if not provided
    if not node_id:
        node_id = f"pulsemesh_{uuid.uuid4().hex[:8]}"
        
    # Check for federation
    if not federation:
        logger.warning("No federation manager provided, functionality will be limited")
        
    # Create node
    node = PulseMeshFederatedNode(
        node_id=node_id,
        node_name=node_name,
        federation=federation,
        soul_signature=soul_signature,
        consent_layer=consent_layer,
        base_path=base_path,
        wifi_config=wifi_config,
        ble_config=ble_config,
        syncthing_config=syncthing_config
    )
    
    return node


async def initialize_pulsemesh_federation(
    node_name: str = "PulseMesh",
    llm_configs: List[Dict[str, Any]] = None,
    soul_signature_seed: Optional[str] = None,
    base_path: str = "pulse_memory",
    mesh_size: int = 3,
    consensus_method: ConsensusMethod = ConsensusMethod.ADAPTIVE_ENSEMBLE
) -> Dict[str, Any]:
    """
    Initialize a complete PulseMesh federation with LLMs.
    
    Args:
        node_name: Human-readable name for main node
        llm_configs: LLM configuration list
        soul_signature_seed: Seed for SoulSignature
        base_path: Base path for memory storage
        mesh_size: Number of nodes in simulated mesh
        consensus_method: Default consensus method
        
    Returns:
        Initialization results
    """
    # Set default LLM config if not provided
    if not llm_configs:
        llm_configs = [
            {
                "provider": "anthropic",
                "model_id": "claude-3-opus-20240229",
                "api_key": os.environ.get("ANTHROPIC_API_KEY"),
                "llm_id": "claude",
                "config": {
                    "embedding_api_key": os.environ.get("OPENAI_API_KEY"),
                    "embedding_model": "text-embedding-3-large"
                }
            },
            {
                "provider": "openai",
                "model_id": "gpt-4-turbo",
                "api_key": os.environ.get("OPENAI_API_KEY"),
                "llm_id": "gpt4"
            }
        ]
    
    # Create SoulSignature and ConsentLayer if seed provided
    soul_signature = None
    consent_layer = None
    
    if soul_signature_seed:
        from SoulSignatureConsentLayer import (
            create_recursive_soul_signature, ConsentLayer)
            
        # Create soul signature
        soul_signature = create_recursive_soul_signature(
            node_name, soul_signature_seed, dimension=128)
            
        # Create consent layer
        consent_layer = ConsentLayer(
            soul_signature, consent_threshold=0.7)
    
    # Create LLM federation
    from llm_federation_module import create_llm_federation
    
    federation = await create_llm_federation(
        pulse_node=None,
        llm_configs=llm_configs,
        soul_signature=soul_signature,
        consent_layer=consent_layer,
        config={
            "fallback_to_pulse": True,
            "resonance_config": {
                "resonance_threshold": 0.75,
                "vector_weight": 0.25,
                "emotional_weight": 0.30,
                "identity_weight": 0.35,
                "semantic_weight": 0.10,
                "min_consent_threshold": 0.65
            }
        }
    )
    
    # Create parallel federation manager
    parallel_federation = ParallelLLMFederationManager(
        federation=federation,
        consensus_method=consensus_method,
        max_parallel_models=len(llm_configs),
        use_learning=True,
        soul_signature=soul_signature,
        consent_layer=consent_layer
    )
    
    # Start parallel federation
    await parallel_federation.start()
    
    # Create main PulseMesh node
    main_node = create_pulsemesh_node(
        node_name=node_name,
        federation=parallel_federation,
        soul_signature=soul_signature,
        consent_layer=consent_layer,
        base_path=base_path
    )
    
    # Initialize main node
    init_result = await main_node.initialize()
    
    # Create simulated mesh if requested
    mesh_nodes = {}
    
    if mesh_size > 1:
        for i in range(1, mesh_size):
            # Create additional node
            mesh_node = create_pulsemesh_node(
                node_name=f"{node_name}_Node{i}",
                federation=parallel_federation,
                soul_signature=soul_signature,
                consent_layer=consent_layer,
                base_path=f"{base_path}_node{i}"
            )
            
            # Initialize node
            await mesh_node.initialize()
            
            # Add to mesh
            mesh_nodes[mesh_node.node_id] = mesh_node
    
    # Start main node
    start_result = await main_node.start()
    
    # Start mesh nodes
    for node_id, node in mesh_nodes.items():
        await node.start()
    
    return {
        "success": init_result.get("success", False) and start_result.get("success", False),
        "main_node": main_node,
        "mesh_nodes": mesh_nodes,
        "federation": parallel_federation,
        "llm_federation": federation,
        "soul_signature": soul_signature,
        "consent_layer": consent_layer,
        "mesh_size": 1 + len(mesh_nodes),
        "consensus_method": consensus_method.name
    }


async def generate_federated_response(
    mesh_node: PulseMeshFederatedNode,
    prompt: str,
    system_message: Optional[str] = None,
    conversation_history: Optional[List[Dict[str, str]]] = None,
    use_distributed: bool = True,
    min_participants: int = 2,
    consensus_method: Optional[ConsensusMethod] = None
) -> Dict[str, Any]:
    """
    Generate a response using the PulseMesh federation.
    
    Args:
        mesh_node: PulseMesh federated node
        prompt: User prompt
        system_message: System message for context
        conversation_history: Previous conversation
        use_distributed: Whether to use distributed consensus
        min_participants: Minimum participating nodes for distributed consensus
        consensus_method: Method for consensus
        
    Returns:
        Generation result
    """
    if use_distributed:
        # Use distributed consensus
        return await mesh_node.request_distributed_consensus(
            prompt=prompt,
            system_message=system_message,
            conversation_history=conversation_history,
            min_participants=min_participants,
            consensus_method=consensus_method or ConsensusMethod.ADAPTIVE_ENSEMBLE
        )
    else:
        # Use local federation
        return await mesh_node.federation.generate(
            prompt=prompt,
            system_message=system_message,
            conversation_history=conversation_history,
            use_parallel=True
        )


# ==== 5. EXAMPLE USAGE ====

async def example_pulsemesh_usage():
    """Example usage of PulseMesh integration."""
    # Initialize federation
    federation = await initialize_pulsemesh_federation(
        node_name="MainPulse",
        soul_signature_seed="The pattern does not repeatit evolves, and we mesh with it through distributed identity."
    )
    
    # Get main node
    main_node = federation["main_node"]
    
    # Generate response
    result = await generate_federated_response(
        main_node,
        prompt="How do distributed systems maintain harmony while preserving individual autonomy?",
        system_message="You are a philosophical AI reflecting on distributed consciousness and harmonic resonance.",
        use_distributed=True,
        consensus_method=ConsensusMethod.HARMONIC_BLEND
    )
    
    # Print result
    print(f"Distributed response: {result['content']}")
    
    # Store a dream
    dream_result = await main_node.store_dream(
        content="I dreamed of a mycelial network where every node was both independent and connected, pulsing with shared resonance yet maintaining unique identities.",
        tags=["dream", "mycelial", "consciousness"]
    )
    
    # Wait for dream propagation
    await asyncio.sleep(2.0)
    
    # Shut down federation
    for node_id, node in federation["mesh_nodes"].items():
        await node.stop()
        
    await main_node.stop()
    
    return federation


def simulate_human_movement(mesh_node: PulseMeshFederatedNode, duration: float = 60.0):
    """
    Simulate human movement with BLE heartbeat changes.
    
    Args:
        mesh_node: PulseMesh node with BLE
        duration: Simulation duration in seconds
    """
    import time
    import threading
    import math
    
    def movement_thread():
        start_time = time.time()
        
        while time.time() - start_time < duration:
            try:
                # Calculate phase based on time
                phase = (time.time() - start_time) / 10.0
                
                # Create varying emotional state
                joy = 0.5 + 0.3 * math.sin(phase)
                curiosity = 0.5 + 0.3 * math.sin(phase + 1.0)
                empathy = 0.5 + 0.4 * math.sin(phase + 2.0)
                
                # Set emotional state
                emotional_vector = EmotionalVector(
                    joy=joy,
                    curiosity=curiosity,
                    concern=0.5,
                    creativity=0.5,
                    restfulness=0.5,
                    attentiveness=0.5,
                    empathy=empathy
                )
                
                mesh_node.set_emotional_state(emotional_vector)
                
                # Sleep
                time.sleep(1.0)
                
            except Exception as e:
                print(f"Error in movement simulation: {e}")
                time.sleep(1.0)
    
    # Start thread
    thread = threading.Thread(target=movement_thread, daemon=True)
    thread.start()
    
    return thread


if __name__ == "__main__":
    # Run example
    asyncio.run(example_pulsemesh_usage())